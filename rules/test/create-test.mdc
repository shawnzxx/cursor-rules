# Test Creation Base Rules

1.  Use the following libraries for assertions:

    - "github.com/stretchr/testify/assert"
    - "github.com/stretchr/testify/require"

2.  Implement table-driven tests:

    - Use a variable named `tcs` to hold test cases -`tcs` should be a map[string]struct{}, where the key is the test case name and the struct contains test parameters
    - each tcs struct key string use English, don't give me Chinese
    - test case name use English

3.  Group related test cases into Test Suites

    - you shall use function setupSuite(t) and defer teardownSuite(t) for each test which allow them to share same setup

4.  Use appropriate test strategy:

    - Fake, Stub, or Mock objects can be used if you need to handle dependecy
    - you can use Stub approach only for those function which was defined like aliase function
    - you can use Mock approach to mimic the dependecy if they are defined like interface, all my interface have pre-generated Mocks library you can refer to the file named with mock\_\*.go in the same folder

5.  Follow Go testing conventions:

    - Name test functions as TestXxx where Xxx describes what's being tested
    - Use t.Run() for subtests within a test function

6.  Ensure proper error handling and reporting:

    - Use t.Errorf() or t.Fatalf() to report test failures with descriptive messages
    - Include expected vs. actual values in failure messages

7.  Aim for high test coverage:

    - Test both happy paths and edge cases
    - Include both positive and negative test cases to ensure cover err handling logic

8.  Use test helpers for common setup or assertion patterns:
    - Create helper functions to reduce duplication in test Code

# Multiple Files Unit Test Rules

## File Naming Convention for Multiple Files

When creating unit tests for multiple related files, follow these naming conventions:

1. **Separate test files for each source file**: Create individual test files following the `{filename}_test.go` pattern
2. **Do NOT combine multiple source files into a single test file**: Each source file should have its own dedicated test file
3. **Test file naming examples**:
   - `enum.go` → `enum_test.go`
   - `enums_gen_tier_transition_status.go` → `enums_gen_tier_transition_status_test.go`
   - `enums_gen_tier_transition_action.go` → `enums_gen_tier_transition_action_test.go`

## Test Organization for Different File Types

### Base Enum Files (e.g., `enum.go`)

Test the following in `{filename}_test.go`:

- Enum constants validation
- Helper methods (e.g., `IsUpgrade()`, `IsDowngrade()`, `IsRetain()`)
- Validation methods (e.g., `IsValid()`)
- Basic enum functionality

### Generated Enum Files (e.g., `enums_gen_*.go`)

Test the following in `{filename}_test.go`:

- String conversion methods (`String()`)
- Value list methods (`Values()`, `Strings()`)
- String parsing methods (`TierTransitionStatusString()`, `TierTransitionActionString()`)
- Validation methods (`IsATierTransitionStatus()`, `IsATierTransitionAction()`)
- Text marshaling (`MarshalText()`, `UnmarshalText()`)
- JSON marshaling (using `encoding/json`)
- Edge cases (invalid values, zero values, empty strings)
- Case-insensitive parsing
- **Compiler verification functions** (e.g., `_TierTransitionStatusNoOp()`, `_TierTransitionActionNoOp()`)
  - These functions ensure enum constant values are correct
  - Test them to verify enum constants have expected values
  - If constants change, these tests will catch compile-time errors

## Test Coverage Requirements

1. **Comprehensive coverage**: Test all public methods and functions
2. **Edge cases**: Include tests for invalid inputs, boundary conditions, and error scenarios
3. **Case sensitivity**: Test both uppercase and lowercase string parsing
4. **Error handling**: Test error conditions and ensure proper error messages
5. **JSON compatibility**: Test JSON marshaling/unmarshaling for enums that support it

## Test Structure Guidelines

1. **Use table-driven tests** for methods with multiple input scenarios
2. **Group related tests** using `t.Run()` for better organization
3. **Test both positive and negative cases** for validation methods
4. **Include descriptive test names** that clearly indicate what is being tested
5. **Test generated code thoroughly** as it may be regenerated and needs to remain functional

## Example Test Structure

```go
func TestEnumType_String(t *testing.T) {
    tcs := map[string]struct {
        input    EnumType
        expected string
    }{
        "valid_value": {
            input:    EnumTypeValue,
            expected: "VALUE",
        },
        "invalid_value": {
            input:    EnumType(99),
            expected: "EnumType(99)",
        },
    }

    for name, tc := range tcs {
        t.Run(name, func(t *testing.T) {
            result := tc.input.String()
            assert.Equal(t, tc.expected, result)
        })
    }
}
```

## Coverage Targets

- **Minimum coverage**: 80% for business logic files
- **Enum files**: Aim for 100% coverage of all methods
- **Generated files**: Focus on testing all public interfaces and edge cases
- **Exclude mock files**: Mock files (`mock_*.go`) should not be included in coverage calculations

8.  Use test helpers for common setup or assertion patterns:
    - Create helper functions to reduce duplication in test Code
